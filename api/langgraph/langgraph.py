import logging
import random
from typing import Dict, List, Any, Optional, Set, Hashable
from enum import Enum

from langchain_openai import ChatOpenAI
from langchain.tools import BaseTool
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph, Graph
from langchain_core.language_models.chat_models import BaseChatModel
from langchain.output_parsers import PydanticOutputParser
from langgraph.prebuilt import create_react_agent
from pydantic import BaseModel, Field

from ..utils import load_property
from ..langchain.memory import MemoryRetriver
from ..tools.query_tools import QueryTools
from ..tools.candidate_tools import CandidateTools

logger = logging.getLogger("bdiviz_flask.sub")


class Candidate(BaseModel):
    sourceColumn: str = Field(description="The source column of the candidate")
    targetColumn: str = Field(description="The target column of the candidate")
    score: float = Field(description="The score of the candidate")
    matcher: str = Field(default="agent", description="The matcher of the candidate")
    status: str = Field(default="idle", description="The status of the candidate")


class AgentState(BaseModel):
    """State for the agent workflow."""
    message: str = Field(default="", description="A string of message (PURE STRING, NO OBJECT-LIKE) of the agent's thoughts")
    query: str = Field(description="The query of the user")
    source_column: Optional[str] = Field(default=None, description="The source column of the query")
    source_values: Optional[List[str]] = Field(default=None, description="The source values of the query")
    target_column: Optional[str] = Field(default=None, description="The target column of the query")
    target_values: Optional[List[str]] = Field(default=None, description="The target values of the query")
    target_description: Optional[str] = Field(default=None, description="The target description of the query")
    # next_agents is a set of agent types that should be called next
    next_agents: Set[str] = Field(default=set(), description="The next agents to call")
    # candidates is a list of candidate that should be passed to the ontology agent, research agent and candidate agent
    candidates: List[Candidate] = Field(default=list(), description="The candidates that should be passed to the ontology agent, research agent and candidate agent")
    # candidates_to_append is a list of candidate that generated by agents
    candidates_to_append: List[Candidate] = Field(default=list(), description="The candidates generated by the agents, passing to the candidate agent")


class OntologyAgentState(BaseModel):
    message: str = Field(default="", description="A string of message (PURE STRING, NO OBJECT-LIKE) of the agent's thoughts")
    candidates_to_append: List[Candidate] = Field(default=list(), description="The candidates that should be append by the candidate agent")


class ResearchAgentState(BaseModel):
    message: str = Field(default="", description="A string of message (PURE STRING, NO OBJECT-LIKE) of the agent's thoughts")
    research_results: List[str] = Field(default=list(), description="The research results that should be passed to the candidate agent")


class AgentType(str, Enum):
    SUPERVISOR = "supervisor"
    ONTOLOGY = "ontology"
    RESEARCH = "research"
    CANDIDATE = "candidate"
    FINAL = "final"


class LangGraphAgent:
    def __init__(self, memory_retriever: MemoryRetriver, session_id: str = "default"):
        # Initialize LLMs
        self.master_llm = ChatOpenAI(model="gpt-4o", temperature=0.2)
        self.worker_llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)
        
        # Initialize tools
        self.memory_retriever = memory_retriever
        self.session_id = session_id

        # Initialize graph
        self.graph = self._build_graph()
    
    def _build_graph(self) -> Graph:
        """Build the LangGraph workflow."""
        # Define the graph
        workflow = StateGraph(AgentState)
        
        # Add nodes
        workflow.add_node("supervisor", self._supervisor_node)
        workflow.add_node("ontology_agent", self._ontology_agent)
        workflow.add_node("research_agent", self._research_agent)
        workflow.add_node("candidate_agent", self._candidate_agent)
        workflow.add_node("final", self._final_node)
        
        # Define routing function
        def route_to_agents(state: AgentState) -> List[Hashable]:
            next_agents = state.next_agents
            return list(next_agents)
        
        # Add conditional edges from supervisor
        workflow.add_conditional_edges(
            "supervisor",
            route_to_agents,
            {
                AgentType.ONTOLOGY: "ontology_agent",
                AgentType.RESEARCH: "research_agent",
                AgentType.CANDIDATE: "candidate_agent",
            }
        )
        
        # Add edges from agents to candidate agent
        workflow.add_edge("ontology_agent", "candidate_agent")
        workflow.add_edge("research_agent", "candidate_agent")
        
        # Add edge from candidate agent to final node
        workflow.add_edge("candidate_agent", "final")
        
        # Set the entry point
        workflow.set_entry_point("supervisor")
        
        # Compile the graph
        return workflow.compile()
    
    def _supervisor_node(self, state: AgentState) -> AgentState:
        """Router node that decides which agents to call next."""
        query = state.query

        source_column = state.source_column
        source_values = state.source_values
        target_column = state.target_column
        target_values = state.target_values

        target_properties = load_property(target_column)
        if target_properties is not None:
            if "enum" in target_properties:
                target_values = target_properties["enum"]
                if len(target_values) >= 50:
                    target_values = random.sample(target_values, 50)
                state.target_values = target_values
            if "description" in target_properties:
                target_description = target_properties["description"]
                if not isinstance(target_description, str):
                    if len(target_description) >= 1:
                        target_description = target_description[0]["description"]
                state.target_description = target_description

        query_tools = QueryTools(self.session_id).get_tools()

        # Determine which agents to route to based on query content
        prompt = f"""
        Analyze the following query and determine which specialized agents should handle it.
        Multiple agents can be called in parallel if needed.
        
        Query: {query}
        
        You are given a source column, source values, target column, target values, and target 
        description. You can use these information to help you determine which agent to route to.
        **Also you can use the tools to get more information about the other candidates exist.**
        
        Source Column: {source_column}
        Source Values: {source_values}
        Target Column: {target_column}
        Target Values: {target_values}
        Target Description: {target_description}
        
        Determine if this is an exploration task or a management task:
        
        1. Exploration Task (include both ONTOLOGY and RESEARCH agents):
           - User wants to find new potential matches
           - User is asking about terminology or definitions
           - User wants to explore related concepts
           - User is looking for additional context
        
        2. Management Task (only include CANDIDATE agent):
           - User wants to filter or remove existing candidates
           - User wants to accept or reject specific matches
           - User wants to update existing candidate information
           - User is making decisions about current candidates
        
        Respond with one or more of: "ontology", "research", "candidate" separated by commas.
        For exploration tasks, include both "ontology" and "research" if relevant.
        For management tasks, only include "candidate".
        If the query doesn't clearly match any category, respond with "candidate" as the default.
        """
        
        agent_state = self._invoke(
            prompt, 
            query_tools, 
            AgentState, 
            self.master_llm, 
            self.memory_retriever
        )

        # Default to candidate agent if no agents were selected
        if not agent_state.next_agents:
            agent_state.next_agents.add(AgentType.CANDIDATE)

        logger.info(f"[LangGraph] Supervisor thoughts: {agent_state.message}")
        
        return agent_state
    
    def _ontology_agent(self, state: AgentState) -> Dict[str, Any]:
        """Agent that handles ontology and terminology searches."""

        logger.info("[LangGraph] Entering ontology agent...")
        
        query = state.query
        
        # Get ontology tools
        ontology_tools = [
            self.memory_retriever.search_ontology_tool,
        ]
        
        prompt = f"""
        Search the ontology for information related to the following query:
        
        Query: {query}
        
        Use the search_ontology tool to find relevant terminology and attribute definitions.

        You should return the candidates_to_append with the candidates that are related to the query.
        """
        
        agent_state = self._invoke(prompt, ontology_tools, OntologyAgentState, self.worker_llm, self.memory_retriever)
        
        logger.info(f"[LangGraph] Ontology agent thoughts: {agent_state.message}")
        message = f"{state.message}\n-----------------------------------\n{agent_state.message}"
        agent_state.message = message
        return {
            "candidates_to_append": agent_state.candidates_to_append
        }

    
    def _research_agent(self, state: AgentState) -> Dict[str, Any]:
        """Agent that handles external research and API calls."""

        logger.info("[LangGraph] Entering research agent...")
        
        query = state.query
        
        # This would typically include tools for external API calls or web searches
        # For now, we'll just return the state unchanged

        logger.info("[LangGraph] Candidate agent thoughts: None")
        
        return {
            "research_results": []
        }
    
    def _candidate_agent(self, state: AgentState) -> AgentState:
        """Agent that handles candidate manipulation."""
        
        logger.info(f"[LangGraph] Entering candidate agent...\nCandidates: {state.candidates}\nCandidates to append: {state.candidates_to_append}\n")

        query = state.query
        source_column = state.source_column
        
        # Get candidate tools
        candidate_tools = CandidateTools(self.session_id).get_tools()
        
        prompt = f"""
        Perform operations on candidates based on the following query:
        
        Query: {query}
        Source Column: {source_column}

        Candidates: {state.candidates}
        Candidates to append: {state.candidates_to_append}
        
        If candidates_to_append exists, use the append_candidates tool to add them to the existing candidates.
        
        If candidates exist, analyze the query's intention carefully and:
        - Use update_candidates if the query suggests modifying existing candidates
        - Use prune_candidates if the query suggests removing certain candidates
        - Use accept_candidates to approve candidates that match the criteria
        - Use reject_candidates to dismiss candidates that don't meet requirements
        
        Make decisions based on semantic relevance, match quality, and the specific intent of the query.
        """
        
        agent_state = self._invoke(prompt, candidate_tools, AgentState, self.master_llm, self.memory_retriever)
        
        logger.info(f"[LangGraph] Candidate agent thoughts: {agent_state.message}")

        message = f"{state.message}\n-----------------------------------\n{agent_state.message}"
        agent_state.message = message
        return agent_state
    
    def _final_node(self, state: AgentState) -> AgentState:
        """Final node that collects results from all agents."""

        logger.info("[LangGraph] Entering final node...")

        # Clear the next_agents to prevent re-execution
        state.next_agents = set()
        return state
    
    def _generate_prompt(self, prompt: str, output_parser: PydanticOutputParser) -> str:
        instructions = output_parser.get_format_instructions()
        template = f"""
Directly return the JSON in the exact schema described below. 
No extra text before or after the JSON.

{instructions}

Prompt: {prompt}
"""
        return template
    
    def _invoke(
        self, prompt: str, tools: List[BaseTool], output_structure: BaseModel, llm: BaseChatModel, store: MemoryRetriver
    ) -> BaseModel:
        output_parser = PydanticOutputParser(pydantic_object=output_structure)

        prompt = self._generate_prompt(prompt, output_parser)
        agent_executor = create_react_agent(
            llm, tools, store=store
        )  # checkpointer=self.memory

        responses = []
        for chunk in agent_executor.stream(
            {
                "messages": [
                    HumanMessage(content=prompt),
                ]
            },
            {"configurable": {"thread_id": "bdiviz-1"}}
        ):
            # logger.info(chunk)
            # logger.info("----")
            responses.append(chunk)

        final_response = responses[-1]["agent"]["messages"][0].content
        response = output_parser.parse(final_response)

        return response
    
    def invoke(self, query: str, source_column: Optional[str] = None, target_column: Optional[str] = None) -> Dict[str, Any]:
        """Invoke the LangGraph workflow with a query."""
        initial_state = AgentState(
            message="",
            query=query,
            source_column=source_column,
            target_column=target_column,
            source_values=None,
            target_values=None,
            target_description=None,
            candidates=[],
            candidates_to_append=[],
            next_agents=set()
        )
        
        # Run the graph
        final_state = self.graph.invoke(initial_state.model_dump())
            
        return final_state