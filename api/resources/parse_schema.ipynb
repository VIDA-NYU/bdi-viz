{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac42f796-ad7b-4dd8-bd2d-409b6070c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%env LANGCHAIN_TRACING_V2=true\n",
    "%env LANGCHAIN_API_KEY=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\n",
    "\n",
    "%env OPENAI_API_KEY=sk-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92058953-1631-4eae-9aea-7ff5b3683be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from typing import Dict, List, TypedDict, Any\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "\n",
    "\n",
    "JSON_SCHEMA_DIR = \"../resources\"\n",
    "JSON_SCHEMA_FILES = [\n",
    "    {\n",
    "        \"name\": \"Genomic Data Commons(GDC)\",\n",
    "        \"filename\": \"better_gdc_schema.json\",\n",
    "        \"jq_schema\": \".\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class RAG:\n",
    "\n",
    "    def __init__(\n",
    "        self, embeddings_model: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    ) -> None:\n",
    "        self.schemas = self.load_json_schemas()\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000, chunk_overlap=200\n",
    "        )\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=embeddings_model)\n",
    "        self.vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "        # Define prompt for question-answering\n",
    "        self.prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    def load_json_schemas(self) -> List[Document]:\n",
    "        schemas = []\n",
    "        for schema in JSON_SCHEMA_FILES:\n",
    "\n",
    "            schema_path = os.path.join(JSON_SCHEMA_DIR, schema[\"filename\"])\n",
    "            loader = JSONLoader(\n",
    "                file_path=schema_path,\n",
    "                jq_schema=schema[\"jq_schema\"],\n",
    "                text_content=False,\n",
    "            )\n",
    "            schema_data = loader.load()\n",
    "            schemas.extend(schema_data)\n",
    "        return schemas\n",
    "\n",
    "    def init_rag(self):\n",
    "        if self.schemas is None or len(self.schemas) == 0:\n",
    "            raise ValueError(\"No schema data found.\")\n",
    "        all_splits = self.text_splitter.split_documents(self.schemas)\n",
    "\n",
    "        # Index chucks\n",
    "        _ = self.vector_store.add_documents(all_splits)\n",
    "\n",
    "    def retrieve(self, state: State):\n",
    "        retrieved_docs = self.vector_store.similarity_search(state[\"question\"])\n",
    "        return {\"context\": retrieved_docs}\n",
    "\n",
    "    def generate(self, state: State, llm: BaseChatModel):\n",
    "        docs_content = \"\\n\\n\".join([doc.page_content for doc in state[\"context\"]])\n",
    "        messages = self.prompt.invoke(\n",
    "            {\n",
    "                \"question\": state[\"question\"],\n",
    "                \"context\": docs_content,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        response = llm.invoke(messages)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ad008-90df-4da5-8d69-3b4af43eebb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loader = JSONLoader(\n",
    "    file_path=\"../resources/better_gdc_schema.json\",\n",
    "    jq_schema=\".\",\n",
    "    text_content=False,\n",
    ")\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c5717e-fd93-4c8c-bc5b-646f99d70f6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rag = RAG()\n",
    "\n",
    "rag.init_rag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d773cbce-0aa5-4abe-8c81-12d924f7f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag.retrieve(State(question=\"What is AJCC?\", context=[], answer=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ec643b-a5b4-4fd5-af17-86bd26374737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461d30df-792a-492c-8268-7d0bb3607a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo  # pip install gitpython\n",
    "\n",
    "git_url = \"https://github.com/NCI-GDC/gdcdictionary.git\"\n",
    "\n",
    "Repo.clone_from(git_url, \"gdc/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e163688-a14a-46f8-97d0-09688a183f56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "gdc_dictionary_path = \"gdc/src/gdcdictionary/schemas\"\n",
    "files = os.listdir(gdc_dictionary_path)\n",
    "\n",
    "yamls = [fi for fi in files if fi.endswith(\".yaml\")]\n",
    "\n",
    "with open(os.path.join(gdc_dictionary_path, \"diagnosis.yaml\"), \"r\") as file:\n",
    "    prime_service = yaml.safe_load(file)\n",
    "\n",
    "prime_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2513c527-8c54-465c-a895-c864cea5f1d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def parse_gdc_yaml(file_name):\n",
    "    with open(file_name, \"r\") as f:\n",
    "        raw = json.load(f)\n",
    "\n",
    "    if raw is None:\n",
    "        return\n",
    "\n",
    "    attrs_ret = []\n",
    "\n",
    "    for subschema, subschema_obj in raw.items():\n",
    "\n",
    "        properties = subschema_obj[\"properties\"]\n",
    "        for attr_name, attr_obj in properties.items():\n",
    "            if attr_name == \"$ref\":\n",
    "                continue\n",
    "            attr_json = {\n",
    "                \"column_name\": attr_name,\n",
    "                \"type\": \"\",\n",
    "                \"description\": extract_description(attr_obj),\n",
    "            }\n",
    "\n",
    "            if \"oneOf\" in attr_obj:\n",
    "                for subtype_obj in attr_obj[\"oneOf\"]:\n",
    "                    if \"enum\" in subtype_obj:\n",
    "                        if \"enum\" not in attr_json:\n",
    "                            attr_json[\"enum\"] = []\n",
    "                        attr_json[\"type\"] = \"enum\"\n",
    "                        attr_json[\"enum\"].extend(subtype_obj[\"enum\"])\n",
    "                    elif subtype_obj[\"type\"] != \"null\":\n",
    "                        print(f\"Hahahahahah ----- {subtype_obj}\")\n",
    "                        type, type_obj = extract_level_one_type(subtype_obj)\n",
    "                        attr_json[\"type\"] = type\n",
    "                        for k, v in type_obj.items():\n",
    "                            attr_json[k] = v\n",
    "            elif \"anyOf\" in attr_obj:\n",
    "                for subtype_obj in attr_obj[\"anyOf\"]:\n",
    "                    if subtype_obj[\"type\"] != \"array\":\n",
    "                        continue\n",
    "                    type, type_obj = extract_level_one_type(subtype_obj)\n",
    "                    attr_json[\"type\"] = type\n",
    "                    for k, v in type_obj.items():\n",
    "                        attr_json[k] = v\n",
    "            else:\n",
    "                type, type_obj = extract_level_one_type(attr_obj)\n",
    "                if type is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    attr_json[\"type\"] = type\n",
    "                    for k, v in type_obj.items():\n",
    "                        attr_json[k] = v\n",
    "            attrs_ret.append(attr_json)\n",
    "    return attrs_ret\n",
    "\n",
    "\n",
    "def extract_level_one_type(attr_obj):\n",
    "    if \"enum\" in attr_obj:\n",
    "        enum_obj = {\"enum\": attr_obj[\"enum\"]}\n",
    "        return (\"enum\", enum_obj)\n",
    "    if \"type\" not in attr_obj:\n",
    "        return (None, {})\n",
    "    if attr_obj[\"type\"] == \"string\":\n",
    "        string_obj = {}\n",
    "        if \"pattern\" in attr_obj:\n",
    "            string_obj[\"pattern\"] = attr_obj[\"pattern\"]\n",
    "        if \"format\" in attr_obj:\n",
    "            string_obj[\"format\"] = attr_obj[\"format\"]\n",
    "        return (\"string\", string_obj)\n",
    "    elif attr_obj[\"type\"] == \"integer\":\n",
    "        number_obj = {}\n",
    "        if \"minimum\" in attr_obj:\n",
    "            number_obj[\"minimum\"] = attr_obj[\"minimum\"]\n",
    "        if \"minimum\" in attr_obj:\n",
    "            number_obj[\"minimum\"] = attr_obj[\"minimum\"]\n",
    "        return (\"integer\", number_obj)\n",
    "    elif attr_obj[\"type\"] == \"number\":\n",
    "        number_obj = {}\n",
    "        if \"minimum\" in attr_obj:\n",
    "            number_obj[\"minimum\"] = attr_obj[\"minimum\"]\n",
    "        if \"minimum\" in attr_obj:\n",
    "            number_obj[\"minimum\"] = attr_obj[\"minimum\"]\n",
    "        return (\"number\", number_obj)\n",
    "    elif attr_obj[\"type\"] == \"boolean\":\n",
    "        return (\"boolean\", {})\n",
    "    elif attr_obj[\"type\"] == \"array\":\n",
    "        array_obj = {\"items\": attr_obj[\"items\"]}\n",
    "        return (\"array\", array_obj)\n",
    "\n",
    "\n",
    "def extract_description(attr_obj):\n",
    "    if \"description\" in attr_obj:\n",
    "        return attr_obj[\"description\"]\n",
    "    elif \"common\" in attr_obj:\n",
    "        if \"description\" in attr_obj[\"common\"]:\n",
    "            return attr_obj[\"common\"][\"description\"]\n",
    "    elif \"enumDef\" in attr_obj:\n",
    "        discriptions = {}\n",
    "        for k, v in attr_obj[\"enumDef\"].items():\n",
    "            discriptions[k] = v[\"description\"]\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "parsed_gdc_json = parse_gdc_yaml(\"../resources/gdc_schema.json\")\n",
    "\n",
    "with open(\"../resources/better_gdc_schema.json\", \"w\") as f:\n",
    "    json.dump(parsed_gdc_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5dcce8-e1a7-4f9e-864d-8c7a224c3ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
